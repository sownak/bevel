# How to debug a Fabric deployment
While deploying a DLT/Blockchain network using BAF, the pods and other components take some time to start. The BAF automation (Ansible component) waits for the components to be at a "Running" or "Completed" state before proceeding with further steps. This is where you can see the message "FAILED - RETRYING: ... "


Each component has a retry count which can be configured in the configuration file (network.yaml). When everything is fine, the components are usually up in 10-15 retries. Meanwhile, you can check the components while the retries occurs to avoid unnecessary wait time till the error/Failed message occurs in Ansible logs.


## BAF Deployment Flowchart:
---

This flow chart shows the BAF Deployment process flow. To verify the steps of deployment, follow the flow chart and check verification table 'C' to troubleshoot the general errors.
![](./../_static/common_flowchart.png)   


### Common Troubleshooting
### (Table 'C')
---

| Section | Sub-section | Problem                                                        | Possible Cause                                                                                                                                           | Solution                                                                                                                                                                                                                                                                                                                                                                                                       |
|---------|-------------|----------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| C1      | a           | Unable to mount config-map **git-auth-{{ network.env.type }}** | Gitops key file path is wrong or file is unreadable by Ansible controller                                                                                | Check the **gitops.private_key** in network.yaml value is an absolute path, and the file is readable by the Ansible controller. Update this for all organizations and re-run the playbook after reset.                                                                                                                                                                                                         |
| C2      | a           | Unable to clone repository                                     | Correct permissions have not been given to the gitops public key                                                                                         | Check that the public key corresponding to the gitops.private_key has been added to the Git repo with read-write permissions. As mentioned [here](https://blockchain-automation-framework.readthedocs.io/en/latest/developer/dev_prereq.html#setting-up-github)                                                                                                                                                |
| C2      | b           | Unable to clone repository                                     | git_shh value is wrong                                                                                                                                   | The **gitops.git_ssh** should be the SSH clone address of the git repository. For example for GitHub it will be like "ssh://git@github.com/<username>/blockchain-automation-framework.git"                                                                                                                                                                                                                     |
| C2      | c           | Unable to clone repository                                     | SSH is blocked from Kubernetes                                                                                                                           | Check that you can clone the git repo using ssh from another pod on the same Kubernetes cluster. If not, check your organization security groups to allow port 22 access outbound                                                                                                                                                                                                                              |
| C2      | d           | No such file or directory                                      | Files are not getting committed to the git repo from Ansible controller                                                                                  | Check **gitops** section of each organization for possible mistakes in branch, password/token, git_push_url etc                                                                                                                                                                                                                                                                                                |
| C2      | e           | No such file or directory                                      | Files are not getting committed to the git repo from Ansible Controller                                                                                  | Check whether git branch is right. Ansible playbook should be run from the same branch as specified in network.yaml in gitops section <br> Check the Ansible logs to see if your local repo is in sync with the remote <br>Check whether the git password/token is valid                                                                                                                                                |
| C2      | f           | The storageclass \"<scname>\" is invalid                       | The storageclass template is wrong and not according to Kubernetes defined rules                                                                         | Check that the new StorageClass template that you have added is valid by manually creating a storage class using the same template. (This error will occur only if you have added or changed the Storageclass template). Refer to [BAF Operations Guide](https://blockchain-automation-framework.readthedocs.io/en/latest/operations/adding_new_storageclass.html)  on how to add a new storage class template |
| C2      | g           | Retries exhausted while waiting for service account to come up | If the flux pod is in crashloopbackoff, and flux pod log mentions  **"extracting public key: Load key \"/etc/fluxd/ssh/identity\": invalid format\r\n"** | Re-create the public/private key for gitops, add the gitops private key path to the network.yaml, add the public key to the repository, reset the network and run again. To reset the network **ansible-playbook platforms/shared/configurations/site.yaml -e "" -e "reset=true"**                                                                                                                             |



#### NOTE:  
If the components are not able to connect to each other, there could be some issue with load balancer. Check the haproxy or external DNS logs for more debugging. Also verify the security groups for any possible conflicts.

If any pod/component of the network is not running (in crashloopbackoff or in error state) or is absent in the get pods list.

Check the flux logs if it has been deployed or not.
Check the helm release. Check the status as well as if the key-values are generated properly.
For further debugging check for pod/container logs.
If components are there but not able to talk to each, check whether the ambasssador/ haproxy is working properly, urls are properly mapped and ports are opened for communication or not.  

---   

## Hyperledger Fabric Checks:

The flow chart shows the Fabric Deployment process. To verify the steps of deployment, follow the verification Table 'F', to troubleshoot the general errors.

![](./../_static/fabric_flowchart.png)

----
### Fabric Troubleshooting
### (Table 'F')

| Section | Sub-section | Problem                                                                                                                                                                                                                                                                                                                                                                                                                           | Possible Cause                                                                                                                         | Solution                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
|---------|-------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| F1      | a           | **Ansible playbook failed after exhausting retry counts or ca pod is in Init:Crashloopbackoff state** <br> Playbook execution terminated at <br> **Role**: create/ca-tools <br> **Task**: Waiting for the CA server to be created in <ORG_NAME>-net <br> **Error**: Retries exhausted                                                                                                                                             | Issues with Vault connectivity                                                                                                         | If the pod **ca-<random_suffix>** has status as **Init:Crashloopbackoff**. Check the logs of the init container **certificates-init** of this pod. This can be checked using the command <br> ``` kubectl logs ca-<random_suffix> -c certificates-init -n <ORG_NAME>-net ```                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| F1      | b           | **Ansible playbook failed after exhausting retry counts or ca pod is in Init:Crashloopbackoff state** <br> Playbook execution terminated at <br> **Role**: create/ca-tools <br> **Task**: Waiting for the CA server to be created in <ORG_NAME>-net <br> **Error**: Retries exhausted                                                                                                                                             | Issue with Vault authentication                                                                                                        | If the logs mention "access denied", make sure that the Vault authentications were created correctly by checking all the tabs on Vault UI. <br> Any Vault authentication problem is because of running different configurations (network.yaml) on the same Vault. Please ensure that you reset the network before re-running with a different network.yaml.                                                                                                                                                                                                                                                                                                                                                                                |
| F1      | c           | **Ansible playbook failed after exhausting retry counts** <br> Playbook execution terminated at <br> **Role**: create/ca_tools <br> **Task**: Waiting for pod ca in <ORG_NAME>-net <br> **Error**: Retry count exhausted <br>                                                                                                                                                                                                     | Storage class is incorrect                                                                                                             | Check the description of the pod **ca-<random_suffix>** under the namespace **<ORG_NAME>-net** . This can be done using the command <br> ``` kubectl describe pod ca-<random_suffix> -n <ORG_NAME>-net ``` <br> If the events (at the end of description says) **"pod has unbound immediate PersistentVolumeClaims (repeated n times)"** then this can possibly check <br> a. If you haven't modified any storage class templates, then check **network.organization.cloud_provider** for incorrect cloud provider <br> b.  If you have modified storage class, please make sure that the storage class works with the mentioned cloud provider under **network.organization.cloud_provider**                                              |
| F2      | a           | **Orderer(s) pods aren't deployed** <br> Ansible playbook failed at <br> **Role**: create/crypto/peer <br> **Task**: Copy tls ca.crt from auto generated path to given path <br> **Error**: Msg: Destination directory <ORDERER_TLS_CERT_DIR> does not exist                                                                                                                                                                      | Orderer TLS certificate path errors or inconsistency with the orderer definitions in the orderer section and the orderer organizations | Ensure the path **network.orderer.certificate** is an accessible (read and write) by the Ansible controller and is an absolute path.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| F2      | b           | **Orderer(s) pods aren't deployed** <br> Ansible playbook failed at <br> **Role**: create/crypto/peer <br> **Task**: Copy tls ca.crt from auto generated path to given path <br> **Error**: Msg: Destination directory <ORDERER_TLS_CERT_DIR> does not exist                                                                                                                                                                      | Orderer TLS certificate path errors or inconsistency with the orderer definitions in the orderer section and the orderer organizations | This also occur only when the orderer section under the organization with type as orderer and the orderer section under **network.orderers** are inconsistent. Check network.yaml and reset and re-run after fixing the inconsistency.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| F2      | c           | **Orderer(s) pods aren't deployed** <br> Playbook executed terminated at <br> **Role**: create/crypto/peer <br> **Task**: Create ambassador credentials <br> **Error**: "error: Cannot read file ./build/crypto-config/peerOrganizations/<ORG_NAME>-net/<PEER_NAME>-<ORG_NAME>-net-certchain.pem, open ./build/crypto-config/peerOrganizations/<ORG_NAME>-net/<PEER_NAME>-<ORG_NAME>-net-certchain.pem: no such file or directory | When having multi peers, the naming convention is incorrect                                                                            | This error usually comes when the peers aren't named in sequential order. BAF currently supports peer naming in sequential order. So if there are 3 peers, they should always be named as peer0, peer1 and peer2. Check network.yaml and reset and re-run after fixing the inconsistency.                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| F2      | d           | **Ansible playbook failed after exhausting retry counts or orderer pod is in Init:Crashloopbackoff state** <br> Playbook execution terminated at <br> **Role**: create/channels <br> **Task**: Waiting for orderer pod <ORDERER_NAME> in <ORG_NAME>-net <br> **Error**: Retries exhausted                                                                                                                                         | Issues with Vault connectivity                                                                                                         | If the pod **<ORDERER_NAME>-0** has status as **Init:Crashloopbackoff**. Check the logs of the init container **certificates-init** of this pod. This can be checked using the command <br> ``` kubectl logs <ORDERER_NAME>-0 -n <ORG_NAME>-net -c certificates-init ```<br> If the logs mention non accessibility of the Vault, make sure that the Vault is up and running and is accessible from the cluster                                                                                                                                                                                                                                                                                                                             |
| F2      | e           | **Ansible playbook failed after exhausting retry counts or orderer pod is in Init:Crashloopbackoff state** <br> Playbook execution terminated at <br> **Role**: create/channels <br> **Task**: Waiting for orderer pod <ORDERER_NAME> in <ORG_NAME>-net <br> **Error**: Retries exhausted                                                                                                                                         | Issues with Vault authentication                                                                                                       | If the logs mention "access denied", make sure that the Vault authentications were created correctly by checking all the tabs on Vault UI. Any Vault authentication problem is because of running different configurations (network.yaml) on the same Vault. Please ensure that you reset the network before re-running with a different network.yaml.                                                                                                                                                                                                                                                                                                                                                                                     |
| F3      | a           | **Ansible playbook failed after exhausting retry counts or peer pod is in Init:Crashloopbackoff state** <br> Playbook execution terminated at <br> **Role**: create/channels <br> **Task**: Waiting for peer pod <PEER_NAME> in <ORG_NAME>-net <br> **Error**: Retries exhausted/stuck                                                                                                                                            | Issue with Vault connectivity                                                                                                          | If the pod **<PEER_NAME>-0** has the status as **Init:Crashloopbackoff**. Check the logs of the init container **certificates-init** of this pod. This can be checked using the command <br> ``` kubectl logs <PEER_NAME>-0 -n <ORG_NAME>-net -c certificates-init ``` <br> If the logs mention non accessibility of the Vault, make sure that the Vault is up and running and is accessible from the cluster                                                                                                                                                                                                                                                                                                                              |
| F3      | b           | **Ansible playbook failed after exhausting retry counts or peer pod is in Init:Crashloopbackoff state** <br> Playbook execution terminated at <br> **Role**: create/channels <br> **Task**: Waiting for peer pod <PEER_NAME> in <ORG_NAME>-net <br> **Error**: Retries exhausted/stuck                                                                                                                                            | Issues with Vault authentication                                                                                                       | If the logs mention "access denied", make sure that the Vault authentications were created correctly by checking all the tabs on Vault UI. Any Vault authentication problem is because of running different configurations (network.yaml) on the same Vault. Please ensure that you reset the network before re-running with a different network.yaml.                                                                                                                                                                                                                                                                                                                                                                                     |
| F4      | a           | **Ansible playbook failed after exhausting retry counts or createchannel job pod is in Init:Crashloopbackoff state** <br> Playbook execution terminated at <br> **Role**: create/channels_join <br> **Task**: waiting for <PEER_NAME> to create channel <CHANNEL_NAME> <br> **Error**: Retries exhausted/stuck                                                                                                                    | Issues with Vault connectivity                                                                                                         | If the pod **createchannel-<CHANNEL_NAME>-<random_suffix>** has the status as **Init:Crashloopbackoff**. Check the logs of the init container **certificates-init** of this pod. This can be checked using the command <br> ``` kubectl logs createchannel-<CHANNEL_NAME>-<random_suffix> -n <ORG_NAME>-net -c certificates-init ``` <br> If the logs mention non accessibility of the Vault, make sure that the Vault is up and running and is accessible from the cluster                                                                                                                                                                                                                                                                |
| F4      | b           | **Ansible playbook failed after exhausting retry counts or createchannel job pod is in Init:Crashloopbackoff state** <br> Playbook execution terminated at <br> **Role**: create/channels_join <br> **Task**: waiting for <PEER_NAME> to create channel <CHANNEL_NAME> <br> **Error**: Retries exhausted/stuck                                                                                                                    | Issue with Vault authentication                                                                                                        | If the logs mention "access denied", make sure that the Vault authentications were created correctly by checking all the tabs on Vault UI. Any Vault authentication problem is because of running different configurations (network.yaml) on the same Vault. Please ensure that you reset the network before re-running with a different network.yaml.                                                                                                                                                                                                                                                                                                                                                                                     |
| F4      | c           | **Create channel pod is in crashloopbackoff or error state** <br> Ansible playbook is stuck on the retries at <br> **Role**: create/channels_join <br> **Task**:  Waiting for <ORG_NAME> to create channel <CHANNEL_NAME> <br> **Error**: Stuck at retries                                                                                                                                                                        | Non-accessibility of proxy URL(s)                                                                                                      | Check the logs of the pod **createchannel-<CHANNEL_NAME>-<random_suffix>**. This can be checked using the command <br> ``` kubectl logs createchannel-<CHANNEL_NAME>-<random_suffix> -n <ORG_NAME>-net ``` <br> If the logs mentions at the end <br> **Error: failed to create deliver client: orderer client failed to connect to <ORDERER_NAME>.<EXTERNAL_URL_SUFFIX>:8443:failed to create new connection: context deadline exceeded** <br> For this error, check the external URL suffix being available and check its access from the security groups of the VPC. <br> This error is not expected when using minikube.                                                                                                                |
| F4      | d           | **Ansible playbook retry count over for the task and no create_channel pod is visible** <br> Ansible playbook exhausted the total retry at <br> **Role**: create/channels_join <br> **Task**:  Waiting for <ORG_NAME> to create channel <CHANNEL_NAME> <br> **Error**: Retry count exhausted                                                                                                                                      | Job failed more than 6 times due to an error                                                                                           | All jobs in BAF disappear if they failed for 6 times. To re-run the jobs, delete the HelmRelease resource using the command <br> ``` kubectl delete hr channel-<ORG_NAME> -n <ORG_NAME>-net ``` <br> and then wait for the pod **createchannel-<CHANNEL_NAME>-<random_suffix>** <br> Once the pods come up, they will fail again, refer to solution mentioned above for possible resolution.                                                                                                                                                                                                                                                                                                                                               |
| F4      | e           | **JoinChannel pod is/are in crashloopbackoff or error state** <br> Ansible playbook is stuck on the retries at <br> **Role**: create/channels_join <br> **Task**: Wait for job joinchannel-<PEER_NAME>-<CHANNEL_NAME> in <ORG_NS> <br> **Error**: Stuck at retries                                                                                                                                                                | Peer has already joined the channel                                                                                                    | Check the logs of the pod **joinchannel-<PEER_NAME>-<CHANNEL_NAME>-<random_suffix>**. This can be checked using the command <br> ``` kubectl logs joinchannel-<PEER_NAME>-<CHANNEL_NAME>-<random_suffix> -n <ORG_NAME>-net ``` <br> If the logs mentions at the end that <br> **Error: proposal failed (err: bad proposal response 500: cannot create ledger from genesis block: LedgerID already exists** <br> For this, reset the network if you want to start fresh and re-run the network. <br> Alternatively, start deploying the ansible playbook from after the task role mentioned in first column.                                                                                                                                |
| F4      | f           | **Ansible playbook retry count over for the task and no join_channel pod is visible** <br> Ansible playbook exhausted the total retry at <br> **Role**: create/channels_join <br> **Task**: Wait for job joinchannel-<PEER_NAME>-<CHANNEL_NAME> in <ORG_NS> <br> **Error**: Retries exhausted                                                                                                                                     | Job failed more than 6 times due to an error                                                                                           | All jobs in BAF disappear if they failed for 6 times. To re-run the jobs, delete the HelmRelease resource using the command <br> ``` kubectl delete hr join-<CHANNEL_NAME>-<ORG_NAME>-<PEER_NAME> -n <ORG_NAME>-net ``` <br> and then wait for the pod **joinchannel-<PEER_NAME>-<CHANNEL_NAME>-<random_suffix>**. Once the pods come up, they will fail again, refer to solution mentioned above for possible resolution.                                                                                                                                                                                                                                                                                                                 |
| F5      | a           | **Ansible playbook failed after exhausting retry counts or anchorpeer job pod is in Init:Crashloopbackoff state** <br> Playbook execution terminated at <br> **Role**: create/chaincode/install <br> **Task**: Waiting for the job anchorpeer-<CHANNEL_NAME>-<ORG_NAME> <br> **Error**: Retries exhausted/stuck                                                                                                                   | Issues with Vault connectivity                                                                                                         | If the pod **anchorpeer-<PEER_NAME>-<CHANNEL_NAME>-<random_suffix>** has the status as **Init:Crashloopbackoff**. Check the logs of the init container **certificates-init** of this pod. This can be checking using the command <br> ``` kubectl logs anchorpeer-<PEER_NAME>-<CHANNEL_NAME>-<random_suffix> -n <ORG_NAME>-net -c certificates-init ``` <br> If the logs mention non accessibility of the Vault, make sure that the Vault is up and running and is accessible from the cluster                                                                                                                                                                                                                                             |
| F6      | a           | **Ansible playbook execution failed after exhausting retry counts or createchannel/joinchannel job pod is in Init:Crashloopbackoff state** <br> Playbook execution failed at <br> **Role**: create/chaincode/instantiate <br> **Task**: Waiting for chaincode to be installed on {{ peer.name }} <br> **Error**: Retry count exhaunted, playbook stopped                                                                          | The chaincode git credentials are wrong/absent                                                                                         | Check the git credentials under **network.organization.services.peer.chaincode.repository** for possible incorrect credentials                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| F6      | b           | **Ansible playbook execution failed after exhausting retry counts or createchannel/joinchannel job pod is in Init:Crashloopbackoff state** <br> Playbook execution failed at <br> **Role**: create/chaincode/instantiate <br> **Task**: Waiting for chaincode to be installed on {{ peer.name }} <br> **Error**: Retry count exhaunted, playbook stopped                                                                          | Issues with Vault connectivity                                                                                                         | If the pod **installchaincode-<PEER_NAME>-<CHAINCODE_NAME>-1-<random_suffix>** or **instantiatechaincode-<PEER_NAME>-<CHAINCODE_NAME>-1-<random_suffix>** has the status as **Init:Crashloopbackoff**. Check the logs of the init container **certificates-init** of this pod. You can check this using the command <br> ``` kubectl logs installchaincode-<PEER_NAME>-<CHAINCODE_NAME>-1-<random_suffix> -n <ORG_NAME>-net -c certificates-init  ```<br> or <br> ```  kubectl logs instantiatechaincode-<PEER_NAME>-<CHAINCODE_NAME>-1-<random_suffix> -n <ORG_NAME>-net -c certificates-init ``` <br> If the logs mention non accessibility of the Vault, make sure that the Vault is up and running and is accessible from the cluster. |
| F7      | a           | **Ansible playbook execution failed** <br> Playbook execution failed at <br> **Role**: create/channels_join <br> **Task**: waiting for {{ peer.name }} to join {{ channel_join }} <br> **Error**: genesis block file not found open allchannel.block: no such file or directory                                                                                                                                                   | The orderer certificates aren't provided/non-accessible/incorrect                                                                      | This error comes when the orderer certificate mentioned in the orderer block **network.orderers[*].certificate** is invalid, the path not readable or contains the wrong tls certificate of orderer. Fix the errors and reset and re-run the playbook.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |


#### Final network validy check
For final checking of the validity of the fabric network.

1. Create a cli pod for any organization. (Now Peer CLI can be enabled from network.yaml itself. Check the [sample network.yaml](./../operations/fabric_networkyaml.md) for reference)

Use this sample template.
```yaml
  metadata:
    namespace: <ORG_NAME>-net
  images:
    fabrictools: hyperledger/fabric-tools:2.0
    alpineutils: index.docker.io/hyperledgerlabs/alpine-utils:1.0
  storage:
    class: <ORG_NAME>sc
    size: 256Mi
  vault:
    role: ault-role
    address: <VAULT_ADDR>
    authpath: <ORG_NAME>-net-auth
    adminsecretprefix: secret/crypto/peerOrganizations/<ORG_NAME>-net/users/admin
    orderersecretprefix: secret/crypto/peerOrganizations/<ORG_NAME>-net/orderer
    serviceaccountname: vault-auth
    imagesecretname: regcred
    tls: false
  peer:
    name: <PEER_NAME>
    localmspid: <ORG_NAME>MSP
    tlsstatus: true
    address: <PEER_NAME>.<ORG_NAME>-net.<EXTERNAL_URL_SUFFIX>:8443
  orderer:
    address: <ORDERER_NAME>
```

2. To install the cli
```
helm install -f cli.yaml /blockchain-automation-framework/platforms/hyperledger-fabric/charts/fabric_cli/ -n <CLI_NAME>
```

3. Get the cli pod
```
export ORG1_NS=<ORG_NAME>-net
export CLI=$(kubectl get po -n ${ORG1_NS} | grep "cli" | awk '{print $1}')
```

4. Copy the cli pod name from the output list and enter the cli using.
```
kubectl exec -it $CLI -n <ORG_NAME>-net -- bash
```

5. To see which chaincodes are installed
```
peer chaincode list --installed (after exec into the cli)
```

6. Check if the chaincode is instantiated or not
```
peer chaincode list --instantiated -C allchannel (after exec into the cli)
```

7. Execute a transaction
For init:
```
peer chaincode invoke -o <orderer url> --tls true --cafile <path of orderer tls cert> -C <channel name> -n <chaincode name> -c '{"Args":[<CHAINCODE_INSTANTIATION_ARGUMENT>]}' (after exec into the cli)
```

Upon successful invocation, should display a `status 200` msg.